# MetaExtract Production Deployment Guide üöÄ

**Date**: January 3, 2026  
**Status**: Production Ready - Enterprise Deployment Guide  
**Version**: 1.0.0

---

## üéØ **Deployment Overview**

This guide covers production deployment of the MetaExtract platform with our enhanced capabilities:
- **134 Format Extensions** across all categories
- **Real-time Progress Tracking** with smooth UX
- **Interactive Dashboards** with quality visualization
- **Enterprise Reliability** with comprehensive monitoring
- **Production-Grade Architecture** with error handling

---

## üìã **Pre-Deployment Checklist**

### **System Requirements**
- [ ] **OS**: Linux (Ubuntu 20.04+), macOS (12+), Windows Server 2019+
- [ ] **Node.js**: 18.x LTS or higher
- [ ] **Python**: 3.11+ with virtual environment
- [ ] **PostgreSQL**: 13+ with connection configured
- [ ] **Redis**: 6+ for caching and sessions
- [ ] **Memory**: 4GB+ available (8GB+ recommended)
- [ ] **Storage**: 10GB+ free space (50GB+ recommended)

### **Dependencies Check**
```bash
# Verify all dependencies are installed
npm --version
python3 --version
node --version
redis-cli ping
psql --version
```

### **Environment Variables**
Create `.env.production` with:
```bash
# Database
DATABASE_URL=postgresql://user:pass@localhost:5432/metaextract_production
REDIS_URL=redis://localhost:6379

# Security
JWT_SECRET=your-super-secret-jwt-key-min-32-chars
SESSION_SECRET=your-super-secret-session-key-min-32-chars

# External Services
DODO_PAYMENTS_API_KEY=your-dodo-payments-api-key
BASE_URL=https://your-domain.com

# Monitoring
SENTRY_DSN=your-sentry-dsn
HEALTH_CHECK_TOKEN=your-health-check-token
```

---

## üöÄ **Deployment Steps**

### **Step 1: Environment Setup**
```bash
# Create production user
sudo useradd -m -s /bin/bash metaextract
sudo usermod -aG sudo metaextract

# Set up directory structure
sudo mkdir -p /opt/metaextract/{app,logs,config,backup}
sudo chown -R metaextract:metaextract /opt/metaextract

# Switch to production user
sudo su - metaextract
```

### **Step 2: Application Deployment**
```bash
# Clone repository
cd /opt/metaextract
git clone https://github.com/your-org/metaextract.git app
cd app

# Install dependencies
npm install --production
python3 -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt

# Build frontend
npm run build
```

### **Step 3: Database Setup**
```bash
# Create production database
sudo -u postgres createdb metaextract_production
sudo -u postgres psql -d metaextract_production -c "
  CREATE USER metaextract WITH PASSWORD 'your-secure-password';
  GRANT ALL PRIVILEGES ON DATABASE metaextract_production TO metaextract;
"

# Run database migrations
npm run db:migrate
npm run db:seed
```

### **Step 4: Redis Setup**
```bash
# Configure Redis for production
sudo systemctl enable redis
sudo systemctl start redis

# Test Redis connection
redis-cli ping
```

### **Step 5: Application Launch**
```bash
# Start application with PM2 for production
npm install -g pm2
pm2 start ecosystem.config.js --env production

# Save PM2 configuration
pm2 save
pm2 startup
```

---

## üîß **Production Configuration**

### **PM2 Ecosystem Configuration** (`ecosystem.config.js`)
```javascript
module.exports = {
  apps: [{
    name: 'metaextract-api',
    script: 'server/index.js',
    instances: 'max', // Use all available CPUs
    exec_mode: 'cluster',
    env: {
      NODE_ENV: 'production',
      PORT: 3000
    },
    error_file: '/opt/metaextract/logs/error.log',
    out_file: '/opt/metaextract/logs/out.log',
    log_file: '/opt/metaextract/logs/combined.log',
    time: true
  }]
};
```

### **Nginx Configuration** (`/etc/nginx/sites-available/metaextract`)
```nginx
server {
    listen 80;
    server_name your-domain.com;
    
    # Redirect HTTP to HTTPS
    return 301 https://$server_name$request_uri;
}

server {
    listen 443 ssl http2;
    server_name your-domain.com;
    
    # SSL Configuration
    ssl_certificate /etc/letsencrypt/live/your-domain.com/fullchain.pem;
    ssl_certificate_key /etc/letsencrypt/live/your-domain.com/privkey.pem;
    
    # Security Headers
    add_header Strict-Transport-Security "max-age=31536000; includeSubDomains" always;
    add_header X-Content-Type-Options "nosniff" always;
    add_header X-Frame-Options "DENY" always;
    add_header X-XSS-Protection "1; mode=block" always;
    
    # Rate Limiting
    limit_req_zone $binary_remote_addr zone=api:10m rate=10r/s;
    limit_req zone=api burst=20 nodelay;
    
    # Proxy Configuration
    location / {
        proxy_pass http://localhost:3000;
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection 'upgrade';
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        proxy_cache_bypass $http_upgrade;
        proxy_buffering off;
    }
    
    # Static Assets
    location /static {
        alias /opt/metaextract/app/client/dist;
        expires 1y;
        add_header Cache-Control "public, immutable";
    }
}
```

---

## üìä **Production Monitoring Setup**

### **System Monitoring** (`monitoring/setup.py`)
```python
#!/usr/bin/env python3
"""Production monitoring setup"""

import psutil
import json
import time
from datetime import datetime
from pathlib import Path

class ProductionMonitor:
    def __init__(self, log_file="/opt/metaextract/logs/monitor.log"):
        self.log_file = Path(log_file)
        self.log_file.parent.mkdir(parents=True, exist_ok=True)
    
    def check_system_health(self) -> Dict[str, Any]:
        """Check overall system health"""
        return {
            'timestamp': datetime.now().isoformat(),
            'cpu_percent': psutil.cpu_percent(interval=1),
            'memory_percent': psutil.virtual_memory().percent,
            'disk_usage': psutil.disk_usage('/').percent,
            'load_average': os.getloadavg() if hasattr(os, 'getloadavg') else [0, 0, 0],
            'process_count': len(psutil.pids())
        }
    
    def check_application_health(self) -> Dict[str, Any]:
        """Check application-specific health"""
        return {
            'timestamp': datetime.now().isoformat(),
            'node_processes': len([p for p in psutil.process_iter(['pid', 'name']) if 'node' in p.info['name']]),
            'redis_connection': self._check_redis(),
            'database_connection': self._check_database(),
            'disk_space_sufficient': psutil.disk_usage('/').free > 5 * 1024 * 1024 * 1024  # 5GB free
        }
    
    def _check_redis(self) -> bool:
        """Check Redis connection"""
        try:
            import redis
            r = redis.Redis(host='localhost', port=6379, decode_responses=True)
            return r.ping()
        except:
            return False
    
    def _check_database(self) -> bool:
        """Check database connection"""
        try:
            import psycopg2
            conn = psycopg2.connect(
                host='localhost',
                database='metaextract_production',
                user='metaextract',
                password='your-secure-password'
            )
            conn.close()
            return True
        except:
            return False
    
    def monitor_loop(self):
        """Main monitoring loop"""
        while True:
            try:
                system_health = self.check_system_health()
                app_health = self.check_application_health()
                
                health_report = {
                    'system': system_health,
                    'application': app_health,
                    'status': 'healthy' if all([
                        system_health['cpu_percent'] < 80,
                        system_health['memory_percent'] < 80,
                        system_health['disk_usage'] < 90,
                        app_health['redis_connection'],
                        app_health['database_connection']
                    ]) else 'degraded'
                }
                
                # Log to file
                with open(self.log_file, 'a') as f:
                    f.write(json.dumps(health_report) + '\n')
                
                # Alert if degraded
                if health_report['status'] == 'degraded':
                    self._send_alert(health_report)
                
                time.sleep(30)  # Check every 30 seconds
                
            except Exception as e:
                print(f"Monitor error: {e}")
                time.sleep(60)  # Wait longer on error
    
    def _send_alert(self, health_report: Dict[str, Any]):
        """Send alert when system is degraded"""
        # This would integrate with your alerting system (PagerDuty, Slack, etc.)
        print(f"ALERT: System health degraded - {health_report}")

if __name__ == "__main__":
    monitor = ProductionMonitor()
    monitor.monitor_loop()
```

### **Health Check Endpoint** (`server/routes/health.ts`)
```typescript
import { Request, Response } from 'express';
import { getDatabase } from '../db';
import { storage } from '../storage/index';
import { getSystemHealth } from '../utils/health-check';

export function registerHealthRoutes(app: Express) {
  // Basic health check
  app.get('/api/health', async (req: Request, res: Response) => {
    try {
      const health = {
        status: 'healthy',
        timestamp: new Date().toISOString(),
        uptime: process.uptime(),
        memory: process.memoryUsage(),
        version: process.version
      };
      
      res.json(health);
    } catch (error) {
      res.status(500).json({ 
        status: 'unhealthy', 
        error: error instanceof Error ? error.message : 'Unknown error' 
      });
    }
  });
  
  // Detailed health check
  app.get('/api/health/detailed', async (req: Request, res: Response) => {
    try {
      const [dbHealth, redisHealth, storageHealth] = await Promise.all([
        checkDatabaseHealth(),
        checkRedisHealth(),
        checkStorageHealth()
      ]);
      
      const detailedHealth = {
        status: dbHealth && redisHealth && storageHealth ? 'healthy' : 'degraded',
        timestamp: new Date().toISOString(),
        components: {
          database: dbHealth,
          redis: redisHealth,
          storage: storageHealth,
          system: getSystemHealth()
        }
      };
      
      res.json(detailedHealth);
    } catch (error) {
      res.status(500).json({ 
        status: 'unhealthy', 
        error: error instanceof Error ? error.message : 'Unknown error' 
      });
    }
  });
}

async function checkDatabaseHealth(): Promise<boolean> {
  try {
    const db = getDatabase();
    await db.select().from(users).limit(1);
    return true;
  } catch {
    return false;
  }
}

async function checkRedisHealth(): Promise<boolean> {
  try {
    return await storage.redis.ping();
  } catch {
    return false;
  }
}

async function checkStorageHealth(): Promise<boolean> {
  try {
    // Check storage backend
    return await storage.healthCheck();
  } catch {
    return false;
  }
}
```

---

## üö® **Alerting & Monitoring**

### **Alert Configuration** (`monitoring/alerts.py`)
```python
#!/usr/bin/env python3
"""Production alerting configuration"""

import json
import requests
from datetime import datetime, timedelta
from typing import Dict, Any, List

class AlertManager:
    def __init__(self, webhook_url: str):
        self.webhook_url = webhook_url
        self.alert_rules = self._load_alert_rules()
    
    def _load_alert_rules(self) -> List[Dict[str, Any]]:
        """Load alert rules from configuration"""
        return [
            {
                'name': 'high_cpu_usage',
                'condition': lambda metrics: metrics['cpu_percent'] > 80,
                'severity': 'warning',
                'message': 'CPU usage is above 80%'
            },
            {
                'name': 'high_memory_usage',
                'condition': lambda metrics: metrics['memory_percent'] > 85,
                'severity': 'critical',
                'message': 'Memory usage is above 85%'
            },
            {
                'name': 'database_connection_lost',
                'condition': lambda metrics: not metrics['database_healthy'],
                'severity': 'critical',
                'message': 'Database connection lost'
            },
            {
                'name': 'high_error_rate',
                'condition': lambda metrics: metrics['error_rate'] > 5,
                'severity': 'warning',
                'message': 'Error rate is above 5%'
            }
        ]
    
    def check_metrics_and_alert(self, metrics: Dict[str, Any]) -> List[Dict[str, Any]]:
        """Check metrics and trigger alerts if necessary"""
        alerts_triggered = []
        
        for rule in self.alert_rules:
            try:
                if rule['condition'](metrics):
                    alert = {
                        'rule_name': rule['name'],
                        'severity': rule['severity'],
                        'message': rule['message'],
                        'timestamp': datetime.now().isoformat(),
                        'metrics': metrics
                    }
                    alerts_triggered.append(alert)
                    self._send_alert(alert)
            except Exception as e:
                print(f"Alert rule error: {e}")
        
        return alerts_triggered
    
    def _send_alert(self, alert: Dict[str, Any]) -> bool:
        """Send alert to configured webhook"""
        try:
            payload = {
                'text': f"üö® MetaExtract Alert: {alert['message']}",
                'attachments': [
                    {
                        'color': self._get_alert_color(alert['severity']),
                        'fields': [
                            {'title': 'Rule', 'value': alert['rule_name'], 'short': True},
                            {'title': 'Severity', 'value': alert['severity'], 'short': True},
                            {'title': 'Timestamp', 'value': alert['timestamp'], 'short': True},
                            {'title': 'Metrics', 'value': json.dumps(alert['metrics'], indent=2), 'short': False}
                        ]
                    }
                ]
            }
            
            response = requests.post(self.webhook_url, json=payload)
            return response.status_code == 200
            
        except Exception as e:
            print(f"Failed to send alert: {e}")
            return False
    
    def _get_alert_color(self, severity: str) -> str:
        """Get color for alert severity"""
        colors = {
            'info': '#36a64f',
            'warning': '#ff9800',
            'critical': '#f44336'
        }
        return colors.get(severity, '#9e9e9e')

# Example usage
if __name__ == "__main__":
    # Slack webhook example
    webhook_url = "https://hooks.slack.com/services/YOUR/WEBHOOK/URL"
    alert_manager = AlertManager(webhook_url)
    
    # Test with sample metrics
    test_metrics = {
        'cpu_percent': 85,
        'memory_percent': 90,
        'database_healthy': False,
        'error_rate': 7.5
    }
    
    alerts = alert_manager.check_metrics_and_alert(test_metrics)
    print(f"Generated {len(alerts)} alerts")
```

---

## üìä **Performance Monitoring**

### **Metrics Collection** (`monitoring/metrics.py`)
```python
#!/usr/bin/env python3
"""Performance metrics collection and analysis"""

import time
import json
from datetime import datetime, timedelta
from typing import Dict, Any, List
from collections import defaultdict, deque

class MetricsCollector:
    def __init__(self, max_history: int = 10000):
        self.max_history = max_history
        self.metrics_history = {
            'extraction_times': deque(maxlen=max_history),
            'error_rates': deque(maxlen=max_history),
            'throughput': deque(maxlen=max_history),
            'memory_usage': deque(maxlen=max_history),
            'user_engagement': deque(maxlen=max_history)
        }
    
    def record_extraction_metric(self, processing_time: float, success: bool, file_size: int) -> None:
        """Record extraction performance metric"""
        self.metrics_history['extraction_times'].append({
            'timestamp': datetime.now().isoformat(),
            'processing_time': processing_time,
            'success': success,
            'file_size': file_size
        })
    
    def record_error_metric(self, error_type: str, file_path: str) -> None:
        """Record error metric"""
        self.metrics_history['error_rates'].append({
            'timestamp': datetime.now().isoformat(),
            'error_type': error_type,
            'file_path': file_path
        })
    
    def calculate_performance_metrics(self, time_range_hours: int = 24) -> Dict[str, Any]:
        """Calculate performance metrics for specified time range"""
        cutoff_time = datetime.now() - timedelta(hours=time_range_hours)
        
        # Filter metrics by time range
        recent_metrics = {
            'extraction_times': [
                m for m in self.metrics_history['extraction_times']
                if datetime.fromisoformat(m['timestamp']) > cutoff_time
            ],
            'error_rates': [
                m for m in self.metrics_history['error_rates']
                if datetime.fromisoformat(m['timestamp']) > cutoff_time
            ]
        }
        
        # Calculate metrics
        extraction_metrics = self._calculate_extraction_metrics(recent_metrics['extraction_times'])
        error_metrics = self._calculate_error_metrics(recent_metrics['error_rates'])
        
        return {
            'time_range': f"{time_range_hours}h",
            'extraction_metrics': extraction_metrics,
            'error_metrics': error_metrics,
            'generated_at': datetime.now().isoformat()
        }
    
    def _calculate_extraction_metrics(self, extraction_times: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Calculate extraction performance metrics"""
        if not extraction_times:
            return {'status': 'no_data'}
        
        processing_times = [m['processing_time'] for m in extraction_times]
        success_count = sum(1 for m in extraction_times if m['success'])
        total_count = len(extraction_times)
        
        return {
            'total_extractions': total_count,
            'successful_extractions': success_count,
            'success_rate': (success_count / total_count) * 100,
            'avg_processing_time': sum(processing_times) / len(processing_times),
            'min_processing_time': min(processing_times),
            'max_processing_time': max(processing_times),
            'median_processing_time': sorted(processing_times)[len(processing_times) // 2]
        }
    
    def _calculate_error_metrics(self, error_records: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Calculate error rate metrics"""
        if not error_records:
            return {'status': 'no_errors'}
        
        error_types = defaultdict(int)
        for error in error_records:
            error_types[error['error_type']] += 1
        
        return {
            'total_errors': len(error_records),
            'error_types': dict(error_types),
            'most_common_error': max(error_types.items(), key=lambda x: x[1])[0] if error_types else 'none'
        }

# Example usage
if __name__ == "__main__":
    collector = MetricsCollector()
    
    # Simulate some metrics
    collector.record_extraction_metric(150.5, True, 1024 * 1024)
    collector.record_extraction_metric(200.3, False, 2048 * 2048)
    collector.record_error_metric('MemoryError', 'test.jpg')
    
    metrics = collector.calculate_performance_metrics(24)
    print(json.dumps(metrics, indent=2))
```

---

## üöÄ **Deployment Validation**

### **Pre-Flight Checklist** (`deployment/validate.py`)
```python
#!/usr/bin/env python3
"""Pre-deployment validation checklist"""

import subprocess
import json
import requests
from pathlib import Path

def validate_deployment():
    """Comprehensive deployment validation"""
    print("üîç Running Pre-Deployment Validation...")
    
    validation_results = {
        'system_checks': [],
        'application_checks': [],
        'integration_checks': [],
        'security_checks': []
    }
    
    # System Checks
    print("\nüìã System Checks:")
    
    # Check disk space
    try:
        result = subprocess.run(['df', '-h', '/'], capture_output=True, text=True)
        disk_usage = result.stdout.split('\n')[1].split()[4]
        disk_ok = int(disk_usage.rstrip('%')) < 90
        validation_results['system_checks'].append({
            'check': 'disk_space',
            'status': 'pass' if disk_ok else 'fail',
            'details': f"Disk usage: {disk_usage}"
        })
    except Exception as e:
        validation_results['system_checks'].append({
            'check': 'disk_space',
            'status': 'error',
            'details': str(e)
        })
    
    # Check memory
    try:
        import psutil
        memory_percent = psutil.virtual_memory().percent
        memory_ok = memory_percent < 85
        validation_results['system_checks'].append({
            'check': 'memory_usage',
            'status': 'pass' if memory_ok else 'fail',
            'details': f"Memory usage: {memory_percent}%"
        })
    except Exception as e:
        validation_results['system_checks'].append({
            'check': 'memory_usage',
            'status': 'error',
            'details': str(e)
        })
    
    # Application Checks
    print("\nüîß Application Checks:")
    
    # Check Node.js processes
    try:
        result = subprocess.run(['pgrep', '-f', 'node'], capture_output=True, text=True)
        node_processes = len(result.stdout.strip().split('\n')) if result.stdout.strip() else 0
        node_ok = node_processes > 0
        validation_results['application_checks'].append({
            'check': 'node_processes',
            'status': 'pass' if node_ok else 'fail',
            'details': f"Node processes: {node_processes}"
        })
    except Exception as e:
        validation_results['application_checks'].append({
            'check': 'node_processes',
            'status': 'error',
            'details': str(e)
        })
    
    # Check database connection
    try:
        import psycopg2
        conn = psycopg2.connect(
            host='localhost',
            database='metaextract_production',
            user='metaextract',
            password='your-secure-password',
            connect_timeout=5
        )
        conn.close()
        validation_results['application_checks'].append({
            'check': 'database_connection',
            'status': 'pass',
            'details': 'Database connection successful'
        })
    except Exception as e:
        validation_results['application_checks'].append({
            'check': 'database_connection',
            'status': 'fail',
            'details': str(e)
        })
    
    # Integration Checks
    print("\nüîó Integration Checks:")
    
    # Check Redis connection
    try:
        import redis
        r = redis.Redis(host='localhost', port=6379, decode_responses=True)
        redis_ok = r.ping()
        validation_results['integration_checks'].append({
            'check': 'redis_connection',
            'status': 'pass' if redis_ok else 'fail',
            'details': 'Redis connection successful'
        })
    except Exception as e:
        validation_results['integration_checks'].append({
            'check': 'redis_connection',
            'status': 'error',
            'details': str(e)
        })
    
    # Security Checks
    print("\nüîí Security Checks:")
    
    # Check SSL certificate
    try:
        import ssl
        import socket
        
        context = ssl.create_default_context()
        with socket.create_connection(('your-domain.com', 443), timeout=5) as sock:
            with context.wrap_socket(sock, server_hostname='your-domain.com') as ssock:
                cert = ssock.getpeercert()
                ssl_ok = cert is not None
                validation_results['security_checks'].append({
                    'check': 'ssl_certificate',
                    'status': 'pass' if ssl_ok else 'fail',
                    'details': 'SSL certificate valid'
                })
    except Exception as e:
        validation_results['security_checks'].append({
            'check': 'ssl_certificate',
            'status': 'error',
            'details': str(e)
        })
    
    # Final validation
    print("\nüìä Validation Results:")
    
    all_passed = True
    for category, results in validation_results.items():
        passed = sum(1 for r in results if r['status'] == 'pass')
        total = len(results)
        
        print(f"{category.replace('_', ' ').title()}: {passed}/{total} passed")
        
        if passed != total:
            all_passed = False
            print("  Failed checks:")
            for result in results:
                if result['status'] != 'pass':
                    print(f"    ‚ùå {result['check']}: {result['details']}")
    
    print(f"\nüéØ Overall Status: {'‚úÖ READY FOR DEPLOYMENT' if all_passed else '‚ùå VALIDATION FAILED'}")
    
    return all_passed

if __name__ == "__main__":
    success = validate_deployment()
    
    if success:
        print("\nüéâ System is ready for production deployment!")
        print("‚úÖ All validation checks passed")
        print("‚úÖ Ready to proceed with production launch")
    else:
        print("\n‚ùå System validation failed")
        print("‚ùå Please address the failed checks before deployment")
        print("‚ùå Run validation again after fixes")
```

---

## üéâ **Deployment Complete!**

### **Post-Deployment Checklist**
- [ ] **Health Monitoring**: Verify all health checks pass
- [ ] **Performance Testing**: Validate performance metrics
- [ ] **User Acceptance**: Test with real users
- [ ] **Monitoring Setup**: Verify alerting system
- [ ] **Backup Verification**: Test backup/restore procedures

### **Next Steps**
1. **Monitor Performance** - Track metrics and optimize
2. **Collect User Feedback** - Improve based on real usage
3. **Scale as Needed** - Handle increased load
4. **Continuous Improvement** - Regular updates and enhancements

**Status**: üöÄ **PRODUCTION DEPLOYMENT COMPLETE - READY FOR LAUNCH!** üéâ

---

## üìû **Support & Maintenance**

### **Emergency Contacts**
- **Technical Team**: tech-team@your-company.com
- **Operations Team**: ops-team@your-company.com
- **On-Call Engineer**: +1-XXX-XXX-XXXX

### **Documentation Links**
- **API Documentation**: https://your-domain.com/docs
- **User Guide**: https://your-domain.com/guide
- **Monitoring Dashboard**: https://your-domain.com/monitoring

### **Monitoring Dashboards**
- **System Health**: https://your-domain.com/health
- **Performance Metrics**: https://your-domain.com/metrics
- **Error Logs**: https://your-domain.com/logs

**Congratulations! Your MetaExtract platform is now production-ready!** üöÄ