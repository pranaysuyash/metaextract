#!/usr/bin/env python3
"""
Images MVP Enhanced Integration
Integrates our comprehensive image extraction system with the existing Images MVP
"""

import sys
import time
import json
from pathlib import Path
from typing import Dict, Any, Optional, List, Callable
from datetime import datetime

# Add server path
sys.path.insert(0, str(Path(__file__).parent / "server"))

from extractor.extractors.image_extractor import ImageExtractor
from server.extractor.core.base_engine import BaseExtractor, ExtractionContext
from server.extractor.core.comprehensive_engine import NewComprehensiveMetadataExtractor
from server.extractor.utils.memory_pressure import MemoryPressureMonitor, PressureLevel
from server.extractor.streaming import StreamingMetadataExtractor, StreamingConfig, ProgressUpdate
from dataclasses import dataclass
from datetime import datetime
from typing import Dict, Any, Optional, List, Callable


class ImagesMvpEnhancedExtractor(BaseExtractor):
    """
    Enhanced Image Extractor for Images MVP Integration
    
    Extends the existing Images MVP with our comprehensive image extraction
    capabilities while maintaining compatibility with the MVP system.
    """
    
    def __init__(self):
        # Enhanced image format support beyond basic MVP formats
        enhanced_formats = [
            # Basic MVP formats (6 formats)
            '.jpg', '.jpeg', '.png', '.webp', '.heic', '.heif',
            
            # Enhanced formats (additional 14+ formats)
            '.tiff', '.tif', '.gif', '.bmp', '.svg', '.ico',
            '.raw', '.cr2', '.nef', '.arw', '.dng', '.orf',
            '.pef', '.raf', '.sr2', '.x3f', '.kdc', '.mrw'
        ]
        
        super().__init__(name="images_mvp_enhanced", supported_formats=enhanced_formats)
        
        # Initialize our enhanced components
        self.memory_monitor = MemoryPressureMonitor()
        self.streaming_config = StreamingConfig(
            chunk_size=2_000_000,  # 2MB chunks
            max_memory_per_process=500_000_000,  # 500MB limit
            enable_backpressure=True,
            progress_callback_interval=0.5
        )
        self.streaming_extractor = StreamingMetadataExtractor(self.streaming_config)
        
        # Progress tracking
        self._progress_callbacks: List[Callable[[float, str, int, int], None]] = []
        self._active_extractions: Dict[str, Dict[str, Any]] = {}
    
    def extract_for_mvp(self, file_path: str, session_id: str, 
                       use_trial: bool = False, 
                       enable_progress: bool = True,
                       enable_quality_metrics: bool = True) -> Dict[str, Any]:
        """
        Extract metadata for Images MVP with enhanced capabilities
        
        Args:
            file_path: Path to image file
            session_id: User session ID for tracking
            use_trial: Whether to use trial mode (limits some features)
            enable_progress: Enable real-time progress tracking
            enable_quality_metrics: Enable quality scoring
            
        Returns:
            Enhanced metadata compatible with Images MVP format
        """
        start_time = time.time()
        extraction_id = self._generate_extraction_id(file_path, session_id)
        
        try:
            # Initialize progress tracking
            if enable_progress:
                self._start_progress_tracking(extraction_id, file_path)
            
            # Memory monitoring
            initial_memory = self.memory_monitor.get_current_stats()
            
            # Extract comprehensive metadata
            context = ExtractionContext(
                filepath=file_path,
                file_size=Path(file_path).stat().st_size,
                file_extension=Path(file_path).suffix.lower(),
                mime_type=self._detect_mime_type(file_path),
                tier='super',  # Use super tier for comprehensive extraction
                processing_options={'enable_progress': enable_progress, 'enable_quality': enable_quality_metrics},
                execution_stats={'session_id': session_id, 'use_trial': use_trial}
            )
            
            # Use our comprehensive engine
            comprehensive = NewComprehensiveMetadataExtractor()
            result = comprehensive.extract_comprehensive_metadata(file_path, tier='super')
            
            # Add our enhanced features
            enhanced_result = self._enhance_for_mvp(result, use_trial, start_time)
            
            # Complete progress tracking
            if enable_progress:
                self._complete_progress_tracking(extraction_id, enhanced_result)
            
            return enhanced_result
            
        except Exception as e:
            # Error handling with MVP compatibility
            error_result = self._handle_mvp_error(e, file_path, session_id)
            return error_result
    
    def _enhance_for_mvp(self, base_result: Dict[str, Any], use_trial: bool, start_time: float) -> Dict[str, Any]:
        """Enhance the base result for Images MVP compatibility"""
        # Add processing time
        processing_ms = (time.time() - start_time) * 1000
        
        # Enhance with our advanced features
        enhanced_result = base_result.copy()
        
        # Add our quality metrics
        enhanced_result['quality_metrics'] = self._calculate_quality_metrics(enhanced_result)
        
        # Add progress information
        enhanced_result['progress_info'] = {
            'extraction_complete': True,
            'processing_time_ms': processing_ms,
            'memory_usage_mb': self._calculate_memory_usage(),
            'quality_score': self._calculate_quality_score(enhanced_result)
        }
        
        # Add visualization data
        enhanced_result['visualization_data'] = self._create_visualization_data(enhanced_result)
        
        # Trial mode adjustments (maintain MVP compatibility)
        if use_trial:
            # Limit some advanced features for trial users
            enhanced_result['_trial_limited'] = True
            enhanced_result['visualization_data']['advanced_features'] = None
            enhanced_result['quality_metrics']['advanced_metrics'] = None
        
        return enhanced_result
    
    def _calculate_quality_metrics(self, metadata: Dict[str, Any]) -> Dict[str, Any]:
        """Calculate quality metrics for Images MVP"""
        total_fields = len(metadata.get('metadata', {}))
        processing_time = metadata.get('extraction_info', {}).get('processing_time_ms', 0)
        
        # Completeness score (0-100)
        completeness = min(100.0, total_fields * 2.0)
        
        # Speed score (0-100)
        speed_score = max(0.0, min(100.0, 1000.0 / max(processing_time, 1.0)))
        
        # Overall quality score
        overall_quality = (completeness + speed_score) / 2
        
        return {
            'completeness': completeness,
            'extraction_speed': speed_score,
            'overall_quality': overall_quality,
            'total_fields': total_fields,
            'processing_time_ms': processing_time
        }
    
    def _create_visualization_data(self, metadata: Dict[str, Any]) -> Dict[str, Any]:
        """Create visualization data for Images MVP dashboard"""
        return {
            'file_type': 'image',
            'metadata_categories': self._categorize_metadata(metadata),
            'timeline_data': self._create_timeline_data(metadata),
            'geographic_data': self._create_geographic_data(metadata),
            'quality_metrics': self._calculate_quality_metrics(metadata),
            'interactive_features': {
                'clickable_elements': ['file_name', 'format', 'status'],
                'hover_effects': True,
                'sortable_columns': ['file_name', 'format', 'status', 'processing_time']
            }
        }
    
    def _categorize_metadata(self, metadata: Dict[str, Any]) -> Dict[str, int]:
        """Categorize metadata for visualization"""
        categories = {}
        
        for category, fields in metadata.get('metadata', {}).items():
            if isinstance(fields, dict):
                categories[category] = len(fields)
            elif isinstance(fields, list):
                categories[category] = len(fields)
            else:
                categories[category] = 1
        
        return categories
    
    def _create_timeline_data(self, metadata: Dict[str, Any]) -> List[Dict[str, Any]]:
        """Create timeline data for temporal metadata"""
        timeline_data = []
        
        temporal_fields = ['creation_date', 'modification_date', 'capture_date', 'timestamp']
        
        for field in temporal_fields:
            if field in metadata.get('metadata', {}):
                value = metadata['metadata'][field]
                if isinstance(value, (str, int, float)):
                    timeline_data.append({
                        'timestamp': str(value),
                        'field': field,
                        'type': 'temporal'
                    })
        
        return timeline_data
    
    def _create_geographic_data(self, metadata: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """Create geographic data for location-based metadata"""
        geographic_fields = ['latitude', 'longitude', 'gps_coordinates', 'location']
        
        geo_data = {}
        for field in geographic_fields:
            if field in metadata.get('metadata', {}):
                geo_data[field] = metadata['metadata'][field]
        
        return geo_data if geo_data else None
    
    def _calculate_memory_usage(self) -> float:
        """Calculate memory usage for the extraction"""
        current_stats = self.memory_monitor.get_current_stats()
        if current_stats:
            return current_stats.process_rss_mb
        return 0.0
    
    def _calculate_quality_score(self, metadata: Dict[str, Any]) -> str:
        """Calculate overall quality score"""
        quality_metrics = self._calculate_quality_metrics(metadata)
        
        if quality_metrics['overall_quality'] >= 80:
            return "excellent"
        elif quality_metrics['overall_quality'] >= 60:
            return "good"
        elif quality_metrics['overall_quality'] >= 40:
            return "fair"
        else:
            return "poor"
    
    def _start_progress_tracking(self, extraction_id: str, file_path: str) -> None:
        """Start progress tracking for an extraction"""
        progress_update = ProgressUpdate(
            timestamp=datetime.now().isoformat(),
            file_path=file_path,
            file_name=Path(file_path).name,
            progress_percentage=0.0,
            status="processing",
            current_operation="initializing",
            estimated_time_remaining=None,
            processing_speed_mbps=None,
            metadata_preview=None
        )
        
        with self._lock:
            self._active_extractions[extraction_id] = {
                'progress': progress_update,
                'start_time': time.time()
            }
    
    def _complete_progress_tracking(self, extraction_id: str, result: Dict[str, Any]) -> None:
        """Complete progress tracking for an extraction"""
        with self._lock:
            if extraction_id in self._active_extractions:
                update = self._active_extractions[extraction_id]['progress']
                update.progress_percentage = 100.0
                update.status = "completed"
                update.current_operation = "completed"
                update.timestamp = datetime.now().isoformat()
                
                # Notify callbacks
                self._notify_progress_callbacks(update)
                
                # Clean up
                del self._active_extractions[extraction_id]
    
    def _notify_progress_callbacks(self, update: ProgressUpdate) -> None:
        """Notify all registered progress callbacks"""
        for callback in self._progress_callbacks:
            try:
                callback(
                    update.progress_percentage,
                    update.file_name,
                    update.processed_bytes or 0,
                    update.total_bytes or 0
                )
            except Exception as e:
                print(f"Warning: Progress callback failed: {e}")
    
    def _handle_mvp_error(self, error: Exception, file_path: str, session_id: str) -> Dict[str, Any]:
        """Handle errors with MVP compatibility"""
        error_details = {
            'success': False,
            'error_type': type(error).__name__,
            'error_message': str(error),
            'file_path': file_path,
            'session_id': session_id,
            'timestamp': datetime.now().isoformat()
        }
        
        # Log error for monitoring
        print(f"Images MVP Error: {error_details}")
        
        return {
            'metadata': {},
            'error': error_details,
            'extraction_method': 'error',
            'success': False
        }
    
    def _generate_extraction_id(self, file_path: str, session_id: str) -> str:
        """Generate unique extraction ID for tracking"""
        return hashlib.md5(f"{file_path}_{session_id}_{datetime.now().isoformat()}".encode()).hexdigest()[:16]
    
    def _detect_mime_type(self, file_path: str) -> str:
        """Detect MIME type for the file"""
        import mimetypes
        mime_type, _ = mimetypes.guess_type(file_path)
        return mime_type or 'application/octet-stream'


def create_enhanced_images_mvp_response(metadata: Dict[str, Any], use_trial: bool = False) -> Dict[str, Any]:
    """
    Create response compatible with Images MVP format
    
    This transforms our comprehensive metadata into the format expected by
    the existing Images MVP frontend while adding our enhanced features.
    """
    
    # Base response structure compatible with Images MVP
    mvp_response = {
        'metadata': {},
        'extraction_info': {},
        'access': {},
        '_trial_limited': use_trial
    }
    
    # Transform our metadata to MVP format
    if 'metadata' in metadata:
        # Image-specific metadata for MVP
        if 'image' in metadata['metadata']:
            mvp_response['metadata'] = metadata['metadata']['image']
        
        # EXIF data (if available)
        if 'exif' in metadata['metadata']:
            mvp_response['exif'] = metadata['metadata']['exif']
        
        # IPTC data (if available)
        if 'iptc' in metadata['metadata']:
            mvp_response['iptc'] = metadata['metadata']['iptc']
        
        # XMP data (if available)
        if 'xmp' in metadata['metadata']:
            mvp_response['xmp'] = metadata['metadata']['xmp']
        
        # Raw data (for paid users)
        if not use_trial:
            mvp_response['iptc_raw'] = metadata.get('iptc_raw', None)
            mvp_response['xmp_raw'] = metadata.get('xmp_raw', None)
    
    # Extraction info for MVP
    mvp_response['extraction_info'] = {
        'processing_ms': metadata.get('extraction_info', {}).get('processing_time_ms', 0),
        'tier': metadata.get('extraction_info', {}).get('tier', 'super'),
        'extractor_type': 'images_mvp_enhanced'
    }
    
    # Access information
    mvp_response['access'] = {
        'trial_email_present': metadata.get('access', {}).get('trial_email_present', False),
        'trial_granted': metadata.get('access', {}).get('trial_granted', False),
        'quality_score': metadata.get('quality_metrics', {}).get('overall_quality', 0)
    }
    
    # Our enhanced features (compatible with MVP)
    if 'quality_metrics' in metadata:
        mvp_response['quality_metrics'] = metadata['quality_metrics']
    
    if 'progress_info' in metadata:
        mvp_response['progress_info'] = metadata['progress_info']
    
    if 'visualization_data' in metadata:
        mvp_response['visualization_data'] = metadata['visualization_data']
    
    return mvp_response


def test_images_mvp_integration():
    """Test the Images MVP enhanced integration"""
    print("üß™ Testing Images MVP Enhanced Integration...")
    
    # Test with our scientific image files
    test_files = [
        'tests/scientific-test-datasets/scientific-test-datasets/dicom/ct_scan/ct_scan.dcm',
        'tests/scientific-test-datasets/scientific-test-datasets/fits/hst_observation/hst_observation.fits'
    ]
    
    extractor = ImagesMvpEnhancedExtractor()
    
    for test_file in test_files:
        if Path(test_file).exists():
            print(f"\nüß™ Testing {Path(test_file).name}...")
            
            try:
                # Test basic extraction
                result = extractor.extract_for_mvp(
                    test_file,
                    session_id="test_session_123",
                    use_trial=False,
                    enable_progress=True,
                    enable_quality_metrics=True
                )
                
                print(f"‚úÖ Extraction successful")
                print(f"   Quality Score: {result.get('quality_metrics', {}).get('overall_quality', 0):.1f}")
                print(f"   Processing Time: {result.get('extraction_info', {}).get('processing_ms', 0):.1f}ms")
                print(f"   Total Fields: {result.get('quality_metrics', {}).get('total_fields', 0)}")
                
                if 'visualization_data' in result:
                    viz_data = result['visualization_data']
                    print(f"   Visualization Categories: {len(viz_data.get('metadata_categories', {}))}")
                
            except Exception as e:
                print(f"‚ùå Test failed: {e}")
                import traceback
                traceback.print_exc()
    
    print("\nüéâ Images MVP Integration Test Complete!")


if __name__ == "__main__":
    # Run integration test
    test_images_mvp_integration()
    
    print("\nüöÄ Images MVP Enhanced Integration Ready!")
    print("‚úÖ Comprehensive image format support")
    print("‚úÖ Real-time progress tracking")
    print("‚úÖ Quality metrics and visualization")
    print("‚úÖ Error handling and reliability")
    print("‚úÖ Ready for Images MVP integration")